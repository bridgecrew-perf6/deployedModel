{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20f-Da5Ew6LN"
   },
   "source": [
    "# **Project Phase 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AobSmNcnNqh"
   },
   "source": [
    "## Part1- Multinomial Logistic Regression from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI3-Xmuu5UNz"
   },
   "source": [
    "**Install the required library.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QnOFUUTn5bOp",
    "outputId": "14153d3a-e807-44db-ecbe-2dc3b2133de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python_speech_features in c:\\users\\khawa\\anaconda3\\lib\\site-packages (0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install python_speech_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rj66P1f15cMo"
   },
   "source": [
    "**Load the required libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CbEfmo_H5exz"
   },
   "outputs": [],
   "source": [
    "import python_speech_features as mfcc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io.wavfile import read\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVBkI6gT5hCL"
   },
   "source": [
    "**Define the MFCC function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UjsQwVpS5kgH"
   },
   "outputs": [],
   "source": [
    "def get_MFCC(audio, sr):\n",
    "    features = mfcc.mfcc(audio, sr, 0.025, 0.01, 13, appendEnergy = True)\n",
    "    return np.mean(features, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUcaJ3ubxQRw"
   },
   "source": [
    "### **Forming Dataset from speech data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aNXGXNGRvIJc",
    "outputId": "31046683-a198-4501-8a1c-630cf9528b5a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a145c0899d7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlX0hWler9wL"
   },
   "source": [
    "### Encoding languages labels (for data being retrieved from a drive link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "3dUjRNlR5_rc",
    "outputId": "997a0462-c0d9-475e-abdb-dbb42080152d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feat_0, feat_1, feat_2, feat_3, feat_4, feat_5, feat_6, feat_7, feat_8, feat_9, feat_10, feat_11, feat_12, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list=[]\n",
    "features=[]\n",
    "l=[]\n",
    "# loading the data from the drive\n",
    "for name in glob.glob(\"/content/drive/My Drive/recordingsData/audio/audios/Recordings-Group 11/*\"):\n",
    " \n",
    "  label=name.split(\"/\")[8].split(\"-\")[0]\n",
    "  recordingno=name.split(\"/\")[8].split(\"-\")[1]\n",
    "  \n",
    "  #calling the MFCC function for getting features\n",
    "  sr, audio = read(name)\n",
    "  features_list=get_MFCC(audio, sr).tolist()\n",
    "\n",
    "  #encoding the data with 0,1,2 values as labels \n",
    "  if(label==\"ur\"):\n",
    "    label=0\n",
    "  elif(label==\"en\"):\n",
    "    label=1\n",
    "  elif(label==\"ue\"):\n",
    "    label=2\n",
    "\n",
    "  features_list.append(label)\n",
    "  features.append(features_list)\n",
    "features\n",
    "\n",
    "#Creating Dataframe \n",
    "df=pd.DataFrame(features, columns = ['feat_0','feat_1','feat_2','feat_3','feat_4','feat_5','feat_6','feat_7','feat_8','feat_9','feat_10','feat_11','feat_12','label'])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.420616</td>\n",
       "      <td>-1.106523</td>\n",
       "      <td>-3.854466</td>\n",
       "      <td>3.577854</td>\n",
       "      <td>-1.386421</td>\n",
       "      <td>-6.628898</td>\n",
       "      <td>-11.955851</td>\n",
       "      <td>-7.753118</td>\n",
       "      <td>-2.687607</td>\n",
       "      <td>-10.298835</td>\n",
       "      <td>6.917660</td>\n",
       "      <td>-7.851081</td>\n",
       "      <td>-6.799251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.420616</td>\n",
       "      <td>-1.106523</td>\n",
       "      <td>-3.854466</td>\n",
       "      <td>3.577854</td>\n",
       "      <td>-1.386421</td>\n",
       "      <td>-6.628898</td>\n",
       "      <td>-11.955851</td>\n",
       "      <td>-7.753118</td>\n",
       "      <td>-2.687607</td>\n",
       "      <td>-10.298835</td>\n",
       "      <td>6.917660</td>\n",
       "      <td>-7.851081</td>\n",
       "      <td>-6.799251</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.643362</td>\n",
       "      <td>-0.229043</td>\n",
       "      <td>-3.130625</td>\n",
       "      <td>-1.625388</td>\n",
       "      <td>-0.224217</td>\n",
       "      <td>0.416528</td>\n",
       "      <td>-6.852738</td>\n",
       "      <td>-9.243361</td>\n",
       "      <td>1.486968</td>\n",
       "      <td>-4.285490</td>\n",
       "      <td>16.338480</td>\n",
       "      <td>-4.966220</td>\n",
       "      <td>-10.124564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.643362</td>\n",
       "      <td>-0.229043</td>\n",
       "      <td>-3.130625</td>\n",
       "      <td>-1.625388</td>\n",
       "      <td>-0.224217</td>\n",
       "      <td>0.416528</td>\n",
       "      <td>-6.852738</td>\n",
       "      <td>-9.243361</td>\n",
       "      <td>1.486968</td>\n",
       "      <td>-4.285490</td>\n",
       "      <td>16.338480</td>\n",
       "      <td>-4.966220</td>\n",
       "      <td>-10.124564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.643362</td>\n",
       "      <td>-0.229043</td>\n",
       "      <td>-3.130625</td>\n",
       "      <td>-1.625388</td>\n",
       "      <td>-0.224217</td>\n",
       "      <td>0.416528</td>\n",
       "      <td>-6.852738</td>\n",
       "      <td>-9.243361</td>\n",
       "      <td>1.486968</td>\n",
       "      <td>-4.285490</td>\n",
       "      <td>16.338480</td>\n",
       "      <td>-4.966220</td>\n",
       "      <td>-10.124564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>12.792125</td>\n",
       "      <td>-7.911104</td>\n",
       "      <td>-11.009741</td>\n",
       "      <td>5.922262</td>\n",
       "      <td>-8.259737</td>\n",
       "      <td>-1.410583</td>\n",
       "      <td>-15.554617</td>\n",
       "      <td>-15.372664</td>\n",
       "      <td>-2.530352</td>\n",
       "      <td>-5.918442</td>\n",
       "      <td>-2.580511</td>\n",
       "      <td>-3.292523</td>\n",
       "      <td>-3.056571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>13.720188</td>\n",
       "      <td>-11.402813</td>\n",
       "      <td>-11.325706</td>\n",
       "      <td>3.983313</td>\n",
       "      <td>-7.455342</td>\n",
       "      <td>-3.671909</td>\n",
       "      <td>-15.862445</td>\n",
       "      <td>-15.744310</td>\n",
       "      <td>0.200963</td>\n",
       "      <td>3.158964</td>\n",
       "      <td>2.918506</td>\n",
       "      <td>-4.339300</td>\n",
       "      <td>-7.697900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>13.512430</td>\n",
       "      <td>-6.669017</td>\n",
       "      <td>-9.888639</td>\n",
       "      <td>4.662860</td>\n",
       "      <td>-14.662137</td>\n",
       "      <td>-5.392384</td>\n",
       "      <td>-14.575046</td>\n",
       "      <td>-12.648510</td>\n",
       "      <td>3.306230</td>\n",
       "      <td>-4.056787</td>\n",
       "      <td>4.018101</td>\n",
       "      <td>1.277110</td>\n",
       "      <td>-9.139446</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>13.507047</td>\n",
       "      <td>-9.687303</td>\n",
       "      <td>-8.127189</td>\n",
       "      <td>3.346995</td>\n",
       "      <td>-12.033723</td>\n",
       "      <td>-6.361372</td>\n",
       "      <td>-16.998146</td>\n",
       "      <td>-12.991586</td>\n",
       "      <td>3.368223</td>\n",
       "      <td>-4.726273</td>\n",
       "      <td>2.225458</td>\n",
       "      <td>3.776183</td>\n",
       "      <td>-9.071092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17379</th>\n",
       "      <td>12.873085</td>\n",
       "      <td>-7.512769</td>\n",
       "      <td>-9.467413</td>\n",
       "      <td>4.601516</td>\n",
       "      <td>-9.554194</td>\n",
       "      <td>-5.635490</td>\n",
       "      <td>-18.552069</td>\n",
       "      <td>-14.932707</td>\n",
       "      <td>3.516842</td>\n",
       "      <td>1.039038</td>\n",
       "      <td>3.808238</td>\n",
       "      <td>-1.950260</td>\n",
       "      <td>-5.106677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17380 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          feat_0     feat_1     feat_2    feat_3     feat_4    feat_5  \\\n",
       "0      15.420616  -1.106523  -3.854466  3.577854  -1.386421 -6.628898   \n",
       "1      15.420616  -1.106523  -3.854466  3.577854  -1.386421 -6.628898   \n",
       "2      15.643362  -0.229043  -3.130625 -1.625388  -0.224217  0.416528   \n",
       "3      15.643362  -0.229043  -3.130625 -1.625388  -0.224217  0.416528   \n",
       "4      15.643362  -0.229043  -3.130625 -1.625388  -0.224217  0.416528   \n",
       "...          ...        ...        ...       ...        ...       ...   \n",
       "17375  12.792125  -7.911104 -11.009741  5.922262  -8.259737 -1.410583   \n",
       "17376  13.720188 -11.402813 -11.325706  3.983313  -7.455342 -3.671909   \n",
       "17377  13.512430  -6.669017  -9.888639  4.662860 -14.662137 -5.392384   \n",
       "17378  13.507047  -9.687303  -8.127189  3.346995 -12.033723 -6.361372   \n",
       "17379  12.873085  -7.512769  -9.467413  4.601516  -9.554194 -5.635490   \n",
       "\n",
       "          feat_6     feat_7    feat_8     feat_9    feat_10   feat_11  \\\n",
       "0     -11.955851  -7.753118 -2.687607 -10.298835   6.917660 -7.851081   \n",
       "1     -11.955851  -7.753118 -2.687607 -10.298835   6.917660 -7.851081   \n",
       "2      -6.852738  -9.243361  1.486968  -4.285490  16.338480 -4.966220   \n",
       "3      -6.852738  -9.243361  1.486968  -4.285490  16.338480 -4.966220   \n",
       "4      -6.852738  -9.243361  1.486968  -4.285490  16.338480 -4.966220   \n",
       "...          ...        ...       ...        ...        ...       ...   \n",
       "17375 -15.554617 -15.372664 -2.530352  -5.918442  -2.580511 -3.292523   \n",
       "17376 -15.862445 -15.744310  0.200963   3.158964   2.918506 -4.339300   \n",
       "17377 -14.575046 -12.648510  3.306230  -4.056787   4.018101  1.277110   \n",
       "17378 -16.998146 -12.991586  3.368223  -4.726273   2.225458  3.776183   \n",
       "17379 -18.552069 -14.932707  3.516842   1.039038   3.808238 -1.950260   \n",
       "\n",
       "         feat_12  label  \n",
       "0      -6.799251      0  \n",
       "1      -6.799251      0  \n",
       "2     -10.124564      0  \n",
       "3     -10.124564      0  \n",
       "4     -10.124564      0  \n",
       "...          ...    ...  \n",
       "17375  -3.056571      0  \n",
       "17376  -7.697900      0  \n",
       "17377  -9.139446      0  \n",
       "17378  -9.071092      0  \n",
       "17379  -5.106677      0  \n",
       "\n",
       "[17380 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"data.csv\",index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBKYPFFJRsDe"
   },
   "source": [
    "### Pre-Processing on Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0Xtvx0hRsGA"
   },
   "source": [
    "#### Dividing data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rKQkNd-NKtZJ"
   },
   "outputs": [],
   "source": [
    "#70:30 train test split\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.3, random_state=42,stratify=df.iloc[:,-1])\n",
    "\n",
    "noofclasses=train_Y.nunique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86SL5wUUsWXb"
   },
   "source": [
    "### Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tM3cq0ob_nsF"
   },
   "outputs": [],
   "source": [
    "\n",
    "for column in train_X:\n",
    "    mean=train_X[column].mean()\n",
    "    std=train_X[column].std()\n",
    "    train_X[column]=train_X[column].apply(lambda x : (x-mean)/std)\n",
    "    test_X[column]=test_X[column].apply(lambda x : (x-mean)/std)\n",
    "\n",
    "train_X.insert(0, 'x0', [1] *train_X.shape[0])\n",
    "test_X.insert(0, 'x0', [1] *test_X.shape[0])\n",
    "test_x=test_X.to_numpy()\n",
    "train_x=train_X.to_numpy()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "FjIaGrx1ucmj",
    "outputId": "0e6122ac-dc3d-49ff-ef4a-1565bd6f25d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.034594</td>\n",
       "      <td>0.366762</td>\n",
       "      <td>-0.827685</td>\n",
       "      <td>-0.271154</td>\n",
       "      <td>-1.587141</td>\n",
       "      <td>-0.864984</td>\n",
       "      <td>0.134636</td>\n",
       "      <td>0.974262</td>\n",
       "      <td>0.437786</td>\n",
       "      <td>-1.540342</td>\n",
       "      <td>-1.446155</td>\n",
       "      <td>-0.476376</td>\n",
       "      <td>0.053531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12038</th>\n",
       "      <td>1</td>\n",
       "      <td>0.230865</td>\n",
       "      <td>-0.644206</td>\n",
       "      <td>1.293990</td>\n",
       "      <td>0.124237</td>\n",
       "      <td>0.323418</td>\n",
       "      <td>0.898725</td>\n",
       "      <td>0.032095</td>\n",
       "      <td>-0.478917</td>\n",
       "      <td>-1.658977</td>\n",
       "      <td>-0.942006</td>\n",
       "      <td>-0.681758</td>\n",
       "      <td>-1.992198</td>\n",
       "      <td>-0.363708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6875</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.109839</td>\n",
       "      <td>0.378543</td>\n",
       "      <td>-0.072632</td>\n",
       "      <td>0.510960</td>\n",
       "      <td>1.250842</td>\n",
       "      <td>-0.741892</td>\n",
       "      <td>-0.388626</td>\n",
       "      <td>-1.446847</td>\n",
       "      <td>-0.455043</td>\n",
       "      <td>1.887859</td>\n",
       "      <td>-0.326499</td>\n",
       "      <td>-0.737787</td>\n",
       "      <td>0.263608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.209958</td>\n",
       "      <td>0.259972</td>\n",
       "      <td>0.146452</td>\n",
       "      <td>-0.915181</td>\n",
       "      <td>-0.106744</td>\n",
       "      <td>0.212596</td>\n",
       "      <td>0.745970</td>\n",
       "      <td>-0.367192</td>\n",
       "      <td>0.423691</td>\n",
       "      <td>-0.033656</td>\n",
       "      <td>0.570992</td>\n",
       "      <td>0.619394</td>\n",
       "      <td>-0.127750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8109</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.406672</td>\n",
       "      <td>0.528298</td>\n",
       "      <td>0.359341</td>\n",
       "      <td>-0.899026</td>\n",
       "      <td>-0.235209</td>\n",
       "      <td>-0.722107</td>\n",
       "      <td>-1.137809</td>\n",
       "      <td>1.172473</td>\n",
       "      <td>-1.627953</td>\n",
       "      <td>-0.401668</td>\n",
       "      <td>-0.712945</td>\n",
       "      <td>-1.196404</td>\n",
       "      <td>-0.420813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6319</th>\n",
       "      <td>1</td>\n",
       "      <td>1.054783</td>\n",
       "      <td>0.350265</td>\n",
       "      <td>1.305708</td>\n",
       "      <td>-0.171091</td>\n",
       "      <td>0.044973</td>\n",
       "      <td>1.190621</td>\n",
       "      <td>-0.264747</td>\n",
       "      <td>2.013026</td>\n",
       "      <td>0.960790</td>\n",
       "      <td>-0.574349</td>\n",
       "      <td>2.484657</td>\n",
       "      <td>1.281566</td>\n",
       "      <td>-1.049303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>1</td>\n",
       "      <td>0.731299</td>\n",
       "      <td>2.154787</td>\n",
       "      <td>0.443587</td>\n",
       "      <td>-0.276432</td>\n",
       "      <td>-1.506395</td>\n",
       "      <td>-1.290420</td>\n",
       "      <td>0.137395</td>\n",
       "      <td>0.509306</td>\n",
       "      <td>0.560822</td>\n",
       "      <td>0.194755</td>\n",
       "      <td>-0.570408</td>\n",
       "      <td>0.818929</td>\n",
       "      <td>-0.032937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12293</th>\n",
       "      <td>1</td>\n",
       "      <td>0.459792</td>\n",
       "      <td>-0.688876</td>\n",
       "      <td>0.150226</td>\n",
       "      <td>0.548306</td>\n",
       "      <td>-0.983173</td>\n",
       "      <td>1.516753</td>\n",
       "      <td>-0.459707</td>\n",
       "      <td>1.836522</td>\n",
       "      <td>-0.750502</td>\n",
       "      <td>0.955106</td>\n",
       "      <td>0.645831</td>\n",
       "      <td>0.750835</td>\n",
       "      <td>0.329191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>1</td>\n",
       "      <td>0.785950</td>\n",
       "      <td>0.120128</td>\n",
       "      <td>-0.238069</td>\n",
       "      <td>-0.197831</td>\n",
       "      <td>0.632455</td>\n",
       "      <td>1.105377</td>\n",
       "      <td>1.187958</td>\n",
       "      <td>-0.104337</td>\n",
       "      <td>1.236566</td>\n",
       "      <td>0.318934</td>\n",
       "      <td>2.531185</td>\n",
       "      <td>-0.533388</td>\n",
       "      <td>-0.767774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11867</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.279157</td>\n",
       "      <td>-1.495921</td>\n",
       "      <td>-1.469713</td>\n",
       "      <td>1.191570</td>\n",
       "      <td>-0.571340</td>\n",
       "      <td>0.733096</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>-0.233583</td>\n",
       "      <td>0.427584</td>\n",
       "      <td>0.371315</td>\n",
       "      <td>0.563980</td>\n",
       "      <td>0.672462</td>\n",
       "      <td>0.549941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12166 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x0    feat_0    feat_1    feat_2    feat_3    feat_4    feat_5  \\\n",
       "11516   1 -0.034594  0.366762 -0.827685 -0.271154 -1.587141 -0.864984   \n",
       "12038   1  0.230865 -0.644206  1.293990  0.124237  0.323418  0.898725   \n",
       "6875    1 -0.109839  0.378543 -0.072632  0.510960  1.250842 -0.741892   \n",
       "2611    1 -1.209958  0.259972  0.146452 -0.915181 -0.106744  0.212596   \n",
       "8109    1 -0.406672  0.528298  0.359341 -0.899026 -0.235209 -0.722107   \n",
       "...    ..       ...       ...       ...       ...       ...       ...   \n",
       "6319    1  1.054783  0.350265  1.305708 -0.171091  0.044973  1.190621   \n",
       "9286    1  0.731299  2.154787  0.443587 -0.276432 -1.506395 -1.290420   \n",
       "12293   1  0.459792 -0.688876  0.150226  0.548306 -0.983173  1.516753   \n",
       "1674    1  0.785950  0.120128 -0.238069 -0.197831  0.632455  1.105377   \n",
       "11867   1 -0.279157 -1.495921 -1.469713  1.191570 -0.571340  0.733096   \n",
       "\n",
       "         feat_6    feat_7    feat_8    feat_9   feat_10   feat_11   feat_12  \n",
       "11516  0.134636  0.974262  0.437786 -1.540342 -1.446155 -0.476376  0.053531  \n",
       "12038  0.032095 -0.478917 -1.658977 -0.942006 -0.681758 -1.992198 -0.363708  \n",
       "6875  -0.388626 -1.446847 -0.455043  1.887859 -0.326499 -0.737787  0.263608  \n",
       "2611   0.745970 -0.367192  0.423691 -0.033656  0.570992  0.619394 -0.127750  \n",
       "8109  -1.137809  1.172473 -1.627953 -0.401668 -0.712945 -1.196404 -0.420813  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "6319  -0.264747  2.013026  0.960790 -0.574349  2.484657  1.281566 -1.049303  \n",
       "9286   0.137395  0.509306  0.560822  0.194755 -0.570408  0.818929 -0.032937  \n",
       "12293 -0.459707  1.836522 -0.750502  0.955106  0.645831  0.750835  0.329191  \n",
       "1674   1.187958 -0.104337  1.236566  0.318934  2.531185 -0.533388 -0.767774  \n",
       "11867 -0.058310 -0.233583  0.427584  0.371315  0.563980  0.672462  0.549941  \n",
       "\n",
       "[12166 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7nYWcVawVWy"
   },
   "source": [
    "#### Functions for Log regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qP2b4fope2_I"
   },
   "outputs": [],
   "source": [
    "def softmax(predictedscores):\n",
    "\n",
    "  #creating an empty arrays of zeros\n",
    "  probabilities=np.zeros((predictedscores.shape[0],noofclasses ))\n",
    "  \n",
    "  \n",
    "  for i in range(predictedscores.shape[0]):\n",
    "      exponents = np.exp(predictedscores[i])\n",
    "      probabilities[i] = exponents / (np.sum(exponents))\n",
    "\n",
    "  return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1yqi1LzJcFfI"
   },
   "outputs": [],
   "source": [
    "#defining the hypothesis h_theta for this case y= QT X which is basicallty the dotproduct of x and theta\n",
    "\n",
    "def hypothesis(featureset, weights):\n",
    "  zscores =  np.zeros((featureset.shape[0],noofclasses ))\n",
    "  for i in range(featureset.shape[0]):\n",
    "    zscores[i] = np.dot(weights, featureset[i])\n",
    "  \n",
    "  return zscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "p26R-i9AcFJt"
   },
   "outputs": [],
   "source": [
    "#the Cross entropy loss function,following the log loss formula for multiclass\n",
    "\n",
    "def crossEntropyLoss(probabilities, truelabels):\n",
    "  ce_loss = 0\n",
    "\n",
    "  for i in range(len(probabilities)):\n",
    "    ce_loss =ce_loss+ (-1*np.log(probabilities[i][truelabels[i]]))\n",
    "  \n",
    "  #averaging loss over the whole dataset\n",
    "  ce_loss = ce_loss / probabilities.shape[0]\n",
    "  return ce_loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "R29NYhzdcFBr"
   },
   "outputs": [],
   "source": [
    "#helper function that returns the arg of the max element in a list\n",
    "def arg_max(probabilities):\n",
    "  l=[]\n",
    "  for i in probabilities:\n",
    "    l.append(np.argmax(i))\n",
    "  l=np.array(l)\n",
    "  return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "pYyBokH-cE2Q"
   },
   "outputs": [],
   "source": [
    "#To predict the labels based on multinomial logistic regression\n",
    "def predict(featureset, weights):\n",
    "  \n",
    "  originalScores = hypothesis(featureset, weights)\n",
    "  probabilities = softmax(originalScores)\n",
    "  predictions = arg_max(probabilities)\n",
    "\n",
    "  return  probabilities, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WfOjWz593OSb"
   },
   "outputs": [],
   "source": [
    "\n",
    "def BatchgradientDescent(featureset, truelabels, alpha, epochs):\n",
    "  J = []\n",
    "  tl={}\n",
    "  \n",
    "  #initializing 2D thetas array randomly \n",
    "  thetas = np.random.rand(noofclasses, featureset.shape[1])\n",
    "\n",
    "  #for subtracting y-hat from the probabilities that are in the true labels \n",
    "  uniquelabels=np.unique(truelabels)\n",
    "  for label in uniquelabels:\n",
    "      tl[label]=np.where(truelabels==label)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "\n",
    "\n",
    "    probabilities, predictions = predict(featureset, thetas)\n",
    "    J.append(crossEntropyLoss(probabilities, truelabels))\n",
    "    \n",
    "    \n",
    "    #subtracting Y hat \n",
    "    for label in tl.keys():\n",
    "      for ids in tl[label][0]:\n",
    "          probabilities[ids][label] =probabilities[ids][label]- 1\n",
    " \n",
    "  \n",
    "  \n",
    "    #calculating gradient descent \n",
    "    grad=np.dot(probabilities.T,featureset)\n",
    "\n",
    "    #updating thetas\n",
    "    for i in range(0,len(thetas)):          \n",
    "            thetas[i]  = thetas[i]  - ( alpha * grad[i] )\n",
    "    \n",
    "\n",
    "\n",
    "  return thetas, J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ttgJSjYvx-W0"
   },
   "outputs": [],
   "source": [
    "def evaluation(predictions, truelabels):\n",
    "\n",
    "\n",
    "    #accuracy\n",
    "    correctPred = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == truelabels[i]:\n",
    "            correctPred += 1\n",
    "    \n",
    "    #decoding labels in predictions and true labels\n",
    "    p=[]\n",
    "    for index, item in enumerate(predictions.tolist()):\n",
    "\n",
    "      if  (predictions[index]==0):\n",
    "          p.append(\"Urdu\")\n",
    "      if  (predictions[index]==1):\n",
    "          p.append(\"English\")\n",
    "      if  (predictions[index]==2):\n",
    "          p.append(\"Mixed\")\n",
    "    t=[]\n",
    "    for index, item in enumerate(truelabels.tolist()):\n",
    "\n",
    "      if  (truelabels[index]==0):\n",
    "          t.append(\"Urdu\")\n",
    "      if  (truelabels[index]==1):\n",
    "          t.append(\"English\")\n",
    "      if  (truelabels[index]==2):\n",
    "          t.append(\"Mixed\")\n",
    "    \n",
    "    pred = pd.Categorical(p, categories=['Urdu', 'English', 'Mixed'])\n",
    "    true = pd.Categorical(t, categories=['Urdu', 'English', 'Mixed'])\n",
    "\n",
    "    cmatrix=pd.crosstab(pred,true,rownames=['Predicted'],colnames=['Actual'])\n",
    "    \n",
    "    \n",
    "    cm=pd.crosstab(true,pred)\n",
    "    #precision\n",
    "    u = cm['Urdu']['Urdu'] /cm['Urdu'].sum()\n",
    "    e = cm['English']['English'] / cm['English'].sum()\n",
    "    m = cm['Mixed']['Mixed'] / cm['Mixed'].sum()\n",
    "    \n",
    "    precision = (u+e+m)/ 3\n",
    "    # print(u )\n",
    "\n",
    "    #Recall\n",
    "    u1 = cmatrix['Urdu']['Urdu'] /cmatrix['Urdu'].sum()\n",
    "    e1 = cmatrix['English']['English'] / cmatrix['English'].sum()\n",
    "    m1 = cmatrix['Mixed']['Mixed'] / cmatrix['Mixed'].sum()\n",
    "\n",
    "    recall=(u1+e1+m1)/3\n",
    "   \n",
    "    #F1 score\n",
    "    F1score = (2 *precision* recall) / (precision + recall)\n",
    "\n",
    "\n",
    "  \n",
    "    accuracy = correctPred/len(predictions)*100\n",
    "    return accuracy,cmatrix,precision,recall,F1score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "z7as4oqH3Llo",
    "outputId": "8478a68f-d5a0-4d4d-e85f-47519079c664"
   },
   "outputs": [],
   "source": [
    "n_epoch = 1500\n",
    "alpha = 0.001\n",
    "\n",
    "thetas,J = BatchgradientDescent(train_x ,train_Y.to_numpy(), alpha, n_epoch)\n",
    "probabilities, predictions = predict(test_x, thetas)\n",
    "accuracy,cmatrix,precision,recall,F1score = evaluation(predictions, test_Y.to_numpy()) \n",
    "\n",
    "display(\"Confusion Matrix\", cmatrix)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy:\",accuracy)\n",
    "print(\"Precision\",precision)\n",
    "print(\"Recall\",recall)\n",
    "print(\"F1 score: \",F1score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-gkOviEOfEb9",
    "outputId": "d02606ac-d453-48a6-e293-e41b07ce05e7"
   },
   "outputs": [],
   "source": [
    "\n",
    "y=[]\n",
    "alphas=0.04\n",
    "x=np.arange(10000,110000,10000)\n",
    "for n_epochs in x:\n",
    "    thetas,J = BatchgradientDescent(train_x ,train_Y.to_numpy(), alphas,n_epochs) \n",
    "    y.append(J)\n",
    "\n",
    "print(J)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "shiHGVSOuw2z",
    "outputId": "94665e91-442d-4f72-ea03-61f7c7b92fe0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "thetas,y = BatchgradientDescent(train_x ,train_Y.to_numpy(), alphas,1500)\n",
    "#2000 epochs \n",
    "\n",
    "\n",
    "x=np.arange(1,1501)\n",
    "plt.plot(x, y)\n",
    " \n",
    "# naming the x axis\n",
    "plt.xlabel('x - axis')\n",
    "# naming the y axis\n",
    "plt.ylabel('y - axis')\n",
    " \n",
    "# giving a title to my graph\n",
    "plt.title('loss against epochs')\n",
    " \n",
    "# function to show the plot\n",
    "plt.show()\n",
    "\n",
    "# the loss drops considerably in the first iterations of the dataset with a learning rate of 0.04 and then stays constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KKk8Z_O2H_e"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCl8cfiLhhM4"
   },
   "source": [
    "## **Part 2 -Sickitlearns Multinomial logistic regression**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PVxm0wOhsZi"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzuZ4Z6Fb_gy"
   },
   "source": [
    "## Initializing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCNYxQoKhw6b"
   },
   "outputs": [],
   "source": [
    "logreg=LogisticRegressionCV(random_state=0, multi_class='multinomial', solver='lbfgs', max_iter=100000,cv=5)\n",
    "logreg.fit(train_X,train_Y)\n",
    "predictions_y = logreg.predict(test_X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyPdz9JpcEdw"
   },
   "source": [
    "## Printing report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "ZVfBkTutmUeA",
    "outputId": "e03a48bf-cea7-4f51-faea-ecd9c4fad8c7"
   },
   "outputs": [],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(test_Y, predictions_y)\n",
    "display(\"Confusion matrix: \",cnf_matrix) \n",
    "print(\"Accuracy:\", accuracy_score(test_Y,  predictions_y)*100)\n",
    "\n",
    "cReport = classification_report(test_Y, predictions_y)\n",
    "print(cReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rowb-LRiUYkw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KhawajaJunaid_22100072_Project phase 1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
